# Agentic Orchestration System# ðŸ¤– Agentic Orchestration System



> **Advanced Multi-Agent Workflow Orchestration with Dual Intelligence Modes**[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)

A sophisticated system for orchestrating multi-workflow solutions with intelligent communication between agents. Choose between **KAG + Conversational Buffer Memory** (LLM-powered intelligence) or **Agentic RAG** (efficient embedding-based retrieval) for optimal workflow coordination.[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)



[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)> **A production-ready AI orchestration platform for building intelligent, multi-agent workflows with comprehensive metrics tracking and real-time monitoring.**

[![FastAPI](https://img.shields.io/badge/FastAPI-latest-green.svg)](https://fastapi.tiangolo.com/)

[![React](https://img.shields.io/badge/React-18.x-61DAFB.svg)](https://reactjs.org/)Build complex AI systems by composing agents, tools, and workflows. Track performance, quality, and execution metrics in real-time. Designed for both developers and researchers.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

---

## ðŸŒŸ Key Features

## ðŸŒŸ Key Features

### ðŸŽ¯ Core Capabilities

### Dual Solution Modes- **Multi-Agent Workflows**: Sequential, parallel, and router-based agent orchestration

- **Dynamic Tool Creation**: 11+ tool templates - create tools programmatically without YAML

#### 1. **Normal Mode: KAG + Conversational Buffer Memory**- **Comprehensive Metrics**: Track 12+ metrics including accuracy, quality, latency, and token usage

- **Knowledge-Augmented Generation** using LangGraph- **Real-Time Monitoring**: WebSocket-based execution tracking with live metrics

- **Gemini LLM-powered** fact extraction and reasoning- **Agent Communication**: Built-in context preservation and memory management (KAG)

- **Full conversational history** maintained across workflows- **Structured Output**: 4 output formats (structured, compact, text, raw) - 80% smaller responses

- **Intelligent handoffs** with context-aware transitions

- **Best for**: General workflows requiring deep intelligence### ðŸ› ï¸ Advanced Features

- **DuckDuckGo Integration**: Built-in web search with region support

#### 2. **Research Mode: Agentic RAG**- **LLM Flexibility**: Support for Groq, Gemini, Anthropic Claude, and more

- **Retrieval-Augmented Generation** with TF-IDF embeddings- **Solution Chains**: Execute multi-workflow solutions with handoff context

- **Zero LLM costs** for storage and retrieval- **Interactive Chat**: Conversational workflows with memory and metrics

- **Chunking strategy** for large document processing (200 words/chunk)- **REST + WebSocket APIs**: Full CRUD operations with real-time updates

- **Agent memory initialization** with full context upfront

- **Best for**: Research-intensive workflows, large documents, cost-sensitive projects---



### Core Capabilities## ðŸš€ Quick Start



- âœ… **Multi-Workflow Solutions** - Chain multiple workflows with intelligent communication### Prerequisites

- âœ… **Dynamic Tool Creation** - Create custom tools on-the-fly- Python 3.9+

- âœ… **Real-time Execution** - WebSocket-based live workflow monitoring- Node.js 16+ (for frontend)

- âœ… **Comprehensive Metrics** - Track performance, tokens, costs- API keys: Groq/Gemini/Anthropic (optional for testing)

- âœ… **Interactive Chat** - Chat-based solution execution

- âœ… **Visual Dashboard** - React-based frontend for management### 1. Install Backend

```powershell

---# Clone repository

git clone https://github.com/Tharunkumar1724/agentic-orchestration-system.git

## ðŸ“Š Architecture Overviewcd agentic-orchestration-system



```# Create virtual environment

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”python -m venv .venv

â”‚                    AGENTIC ORCHESTRATION SYSTEM                  â”‚.\.venv\Scripts\Activate.ps1

â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

â”‚                                                                  â”‚# Install dependencies

â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚pip install -r requirements.txt

â”‚  â”‚   Frontend     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Backend      â”‚                 â”‚

â”‚  â”‚   (React)      â”‚         â”‚   (FastAPI)    â”‚                 â”‚# Configure environment

â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚copy .env.example .env

â”‚                                       â”‚                          â”‚# Edit .env and add your API keys

â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚```

â”‚                        â–¼                             â–¼          â”‚

â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚### 2. Start Backend Server

â”‚              â”‚  NORMAL MODE    â”‚         â”‚ RESEARCH MODE   â”‚   â”‚```powershell

â”‚              â”‚  (KAG)          â”‚         â”‚ (Agentic RAG)   â”‚   â”‚# Option 1: Using start script

â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚.\start_backend.ps1

â”‚                       â”‚                           â”‚             â”‚

â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚# Option 2: Manual start

â”‚              â”‚ LangGraph       â”‚         â”‚ TF-IDF          â”‚   â”‚uvicorn app.main:app --reload --port 8000

â”‚              â”‚ Pipeline        â”‚         â”‚ Embeddings      â”‚   â”‚```

â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”‚

â”‚              â”‚ â€¢ Gemini LLM    â”‚         â”‚ â€¢ Chunking      â”‚   â”‚### 3. Start Frontend Dashboard (Optional)

â”‚              â”‚ â€¢ Fact Extract  â”‚         â”‚ â€¢ Similarity    â”‚   â”‚```powershell

â”‚              â”‚ â€¢ Reasoning     â”‚         â”‚ â€¢ Retrieval     â”‚   â”‚cd frontend

â”‚              â”‚ â€¢ Summaries     â”‚         â”‚ â€¢ No LLM Cost   â”‚   â”‚npm install

â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚npm start

â”‚                                                                  â”‚# Access at http://localhost:3000

â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜```

```

### 4. Try It Out

---```powershell

# Run example workflow

## ðŸš€ Quick Startpython example_complete_workflow.py



### Prerequisites# Test metrics system

python test_metrics_complete.py

- Python 3.8+

- Node.js 16+# Interactive tool creator

- Google Gemini API key (optional for Normal mode)python interactive_tool_creator.py

```

### Installation

---

1. **Clone the repository**

```bash## ðŸ“Š Metrics System

git clone https://github.com/Tharunkumar1724/agentic-orchestration-system.git

cd agentic-orchestration-system/agentic_appTrack **12+ comprehensive metrics** across all executions:

```

### Performance Metrics

2. **Backend Setup**- **Latency**: Execution time in milliseconds

```bash- **Token Usage**: Input/output/total token counts

# Install dependencies- **Tool Invocations**: Count and success rate

pip install -r requirements.txt

### Quality Metrics

# Configure your API key (optional for Research mode)- **Accuracy**: Task completion accuracy (0-100%)

echo "GEMINI_API_KEY=your_api_key_here" > .env- **Response Quality**: Output quality score

```- **Hallucination Rate**: Factual accuracy tracking

- **Context Quality**: Relevance and coherence

3. **Frontend Setup**

```bash### Execution Metrics

cd frontend- **Task Completion Rate**: Success percentage

npm install- **Decision Depth**: Reasoning complexity

```- **Branching Factor**: Workflow complexity

- **Retrieval Errors**: Data access failures

### Running the System

**View Metrics**: Automatically displayed in workflow results, solution execution, and chat responses.

**Option 1: Use PowerShell scripts (Windows)**

```powershell---

.\start.ps1  # Starts both backend and frontend

```## ðŸŽ¨ Output Formats



**Option 2: Manual start**Choose the format that fits your needs:



Terminal 1 - Backend:```bash

```bash# Structured (default) - Clean JSON with summary

python run.pycurl -X POST "http://localhost:8000/v1/workflows/my-workflow/run"

# Backend runs on http://localhost:8000

```# Compact - 80% smaller, essential data only

curl -X POST "http://localhost:8000/v1/workflows/my-workflow/run?format=compact"

Terminal 2 - Frontend:

```bash# Text - Human-readable report

cd frontendcurl -X POST "http://localhost:8000/v1/workflows/my-workflow/run?format=text"

npm start

# Frontend runs on http://localhost:3000# Raw - Full technical details

```curl -X POST "http://localhost:8000/v1/workflows/my-workflow/run?format=raw"

```

Access the dashboard at: **http://localhost:3000**

---

---

## ðŸ› ï¸ Dynamic Tool Creation

## ðŸ“– Solution Modes Explained

Create tools on-the-fly without YAML files:

### Normal Mode: KAG + Conversational Buffer Memory

```python

**Knowledge-Augmented Generation** with LangGraph orchestration.from agentic_tool_client import AgenticToolClient



**How it Works:**client = AgenticToolClient()



```# Create a web search tool

Workflow 1 Executessearch_tool = client.create_duckduckgo_search(

        â†“    name="Web Search",

Extract Facts (Gemini LLM)    max_results=5,

        â†“    region="us-en"

Generate Summary (Gemini LLM))

        â†“

Store in Conversational Buffer# Create an API tool

        â†“api_tool = client.create_rest_api_tool(

Workflow 2 Executes    name="GitHub API",

        â†“    endpoint="https://api.github.com/users/{username}",

Retrieve FULL Context from Buffer    method="GET"

        â†“)

Intelligent Handoff (Gemini Reasoning)

        â†“# Use in workflow

Continue with Complete Historyworkflow = client.create_workflow(

```    name="Research Workflow",

    agents=[...],

**Key Components:**    tools=[search_tool["tool"]["id"], api_tool["tool"]["id"]]

)

1. **LangGraph Pipeline**```

   - `retrieve_context`: Gets previous workflow memory

   - `extract_facts`: Uses Gemini to extract structured facts**11 Tool Templates Available:**

   - `generate_summary`: Creates intelligent summaries- DuckDuckGo Search, REST API, GraphQL, Web Scraper

   - `store_memory`: Saves to conversational buffer- Database (SQL), File Reader, File Writer

- Python Executor, Shell Command, HTTP Request, Custom

2. **Conversational Buffer Memory**

   - Maintains full conversation history---

   - Accumulates context progressively

   - Provides complete solution context## ðŸ“š Documentation



3. **Gemini-Powered Intelligence**### Getting Started

   - Fact extraction with context understanding- **[Quick Start Guide](QUICK_START.md)** - Get up and running in 5 minutes

   - Reasoning about workflow relationships- **[Complete Guide](GETTING_STARTED.md)** - Comprehensive setup and usage

   - Human-like summaries- **[API Reference](COMPLETE_URL_API_REFERENCE.md)** - Full REST API documentation

   - Intelligent handoff decisions

### Core Features

**Example Use Case:**- **[Metrics System](METRICS_SYSTEM_COMPLETE.md)** - Comprehensive metrics tracking

```python- **[Output Formatting](OUTPUT_FORMATTING_GUIDE.md)** - Structured output formats

# Create a Normal mode solution- **[Dynamic Tools](DYNAMIC_TOOL_CREATION_GUIDE.md)** - Create tools programmatically

solution = {- **[Workflow Communication](WORKFLOW_COMMUNICATION_COMPLETE.md)** - Agent-to-agent messaging

    "name": "Market Analysis Pipeline",

    "solution_type": "normal",  # KAG + Buffer### Advanced Topics

    "workflows": ["data_collection", "trend_analysis", "report_generation"]- **[Solution Chains](SOLUTION_SYSTEM_COMPLETE.md)** - Multi-workflow orchestration

}- **[Chat Mode](CHAT_MODE.md)** - Conversational workflows

- **[KAG Service](ARCHITECTURE_COMPLETE_SUMMARY.md)** - Knowledge-aided generation

# Workflow 1: Data Collection- **[Frontend Guide](COMPLETE_FRONTEND_GUIDE.md)** - Dashboard setup

# Output: "Collected 500 data points from NYSE..."

# KAG extracts: ["NYSE data", "500 points", "Tech up 5%"]### Quick References

- **[Metrics Quick Ref](OUTPUT_FORMAT_QUICKREF.md)** - Metrics at a glance

# Workflow 2: Trend Analysis- **[DuckDuckGo Quick Ref](DUCKDUCKGO_QUICK_REF.md)** - Web search usage

# Receives: Full context + extracted facts + summary- **[Execution Quick Ref](EXECUTION_QUICK_REFERENCE.md)** - Workflow execution

# Uses Gemini reasoning for intelligent analysis

```---



**Metrics:**## ðŸ—ï¸ Architecture

- LLM API Calls: 2-3 per workflow

- Cost: $$ (API fees)```

- Data Transfer: Full context (~2-5 KB per workflow)â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

- Processing Time: Medium (network latency)â”‚                   Frontend Dashboard                â”‚

â”‚         (React + ReactFlow + WebSocket)             â”‚

---â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                   â”‚ REST API + WebSocket

### Research Mode: Agentic RAGâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

â”‚              FastAPI Backend (Python)               â”‚

**Retrieval-Augmented Generation** with TF-IDF embeddings and intelligent chunking.â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

â”‚  â”‚  Orchestrator (LangGraph)                     â”‚  â”‚

**How it Works:**â”‚  â”‚  - Workflow Execution Engine                  â”‚  â”‚

â”‚  â”‚  - Metrics Tracking (MetricsService)          â”‚  â”‚

```â”‚  â”‚  - Agent Communication (KAG)                  â”‚  â”‚

Workflow 1 Executes (Large Document)â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

        â†“â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚

Chunk Text (~200 words per chunk)â”‚  â”‚  Services Layer                               â”‚  â”‚

        â†“â”‚  â”‚  - LLM Clients (Groq/Gemini/Claude)           â”‚  â”‚

Create TF-IDF Embeddings (No LLM!)â”‚  â”‚  - Tool Manager (11+ templates)               â”‚  â”‚

        â†“â”‚  â”‚  - Storage (YAML + JSON)                      â”‚  â”‚

Store in Vector Storeâ”‚  â”‚  - Output Formatter (4 formats)               â”‚  â”‚

        â†“â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚

Workflow 2 Agent Startsâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        â†“```

Create Query Vector from Description

        â†“**Tech Stack:**

Similarity Search (Cosine)- **Backend**: FastAPI, LangGraph, Pydantic

        â†“- **Frontend**: React, ReactFlow, Framer Motion, Tailwind CSS

Retrieve Top-K Chunks (>10% similarity)- **LLMs**: Groq (Llama), Google Gemini, Anthropic Claude

        â†“- **Storage**: YAML (configs), JSON (runs), In-memory (sessions)

INITIALIZE AGENT MEMORY with FULL CONTEXT

        â†“---

Agent Executes with Complete Relevant Info

```## ðŸ”§ Configuration



**Key Components:**### LLM Providers



1. **Chunking Strategy****Groq (Default)**

   - Fixed-size word-based chunking (200 words default)```bash

   - Preserves word boundariesLLM_PROVIDER=groq

   - No overlap between chunksGROQ_API_KEY=your-groq-key

   - Fast O(n) implementation```



2. **TF-IDF Embeddings****Google Gemini**

   - Term Frequency calculation per chunk```bash

   - Inverse Document Frequency across chunksLLM_PROVIDER=gemini

   - Sparse vector representationGEMINI_API_KEY=your-gemini-key

   - **Zero LLM cost**```



3. **Similarity Search****Anthropic Claude**

   - Cosine similarity computation```bash

   - Threshold-based filtering (10% default)LLM_PROVIDER=anthropic

   - Top-K retrieval (K=3 default)ANTHROPIC_API_KEY=your-claude-key

   - Fast mathematical operationsANTHROPIC_MODEL=claude-sonnet-4.5

```

4. **Agent Memory Initialization**

   - **Full context delivered at startup**### Environment Variables

   - Not incremental or on-demand```bash

   - Complete package with similarity scores# Required

   - Source attribution includedGROQ_API_KEY=gsk_...           # For Groq LLMs

GEMINI_API_KEY=AI...           # For Gemini LLMs (optional)

**Example Use Case:**

```python# Optional

# Create a Research mode solutionLLM_PROVIDER=groq              # groq, gemini, anthropic

solution = {PORT=8000                      # Backend server port

    "name": "Academic Research Pipeline",FRONTEND_PORT=3000             # Frontend dashboard port

    "solution_type": "research",  # Agentic RAG```

    "workflows": ["paper_scraping", "literature_review", "synthesis"]

}---



# Workflow 1: Paper Scraping## ðŸ§ª Testing

# Output: 10,000 words of research content

# Chunked into: 50 chunks (~200 words each)```powershell

# TF-IDF indexed: 226 unique terms# Test metrics system

python test_metrics_complete.py

# Workflow 2: Literature Review Agent

# Agent Memory Initialized with:# Test dynamic tools

# - Top 3 relevant chunks (12.2%, 8.7%, 6.3% similarity)python test_dynamic_tools.py

# - 600 bytes transferred (6% of original)

# - FULL context upfront, not incremental# Test output formatting

```python test_formatted_output.py



**Metrics:**# Test solution execution

- LLM API Calls: 0 (for storage/retrieval)python test_solution_websocket_quick.py

- Cost: $0

- Data Transfer: Only relevant chunks (3-5% of original)# Test complete orchestration

- Processing Time: Fast (<100ms)python test_complete_orchestration.py

- Efficiency: **96% data reduction**```



------



## ðŸ“Š Performance Comparison## ðŸ¤ Contributing



### Test Results (Real Data)We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.



**Input:** 4.94 KB of text (2 workflows)**Ways to Contribute:**

- ðŸ› Report bugs and issues

| Metric | Normal (KAG) | Research (RAG) |- ðŸ’¡ Suggest new features

|--------|--------------|----------------|- ðŸ“ Improve documentation

| **LLM API Calls** | 4-6 | 0 |- ðŸ”§ Submit pull requests

| **Cost** | ~$0.05 | $0.00 |- â­ Star the repository

| **Processing Time** | 2-3 sec | <100 ms |

| **Data to Agent** | 2.2 KB (full) | 200 bytes (relevant) |---

| **Transfer Efficiency** | 100% | 3.95% |

| **Fact Quality** | High (LLM) | Medium (heuristic) |## ðŸ“¦ Project Structure

| **Context Delivery** | Real-time | Upfront |

| **Memory Usage** | Medium | Low |```

agentic_app/

### Data Transfer Analysisâ”œâ”€â”€ app/

â”‚   â”œâ”€â”€ main.py                 # FastAPI application

**Normal Mode:**â”‚   â”œâ”€â”€ routers/                # API endpoints

```â”‚   â”‚   â”œâ”€â”€ workflows.py        # Workflow CRUD + execution

Original: 4.94 KBâ”‚   â”‚   â”œâ”€â”€ solutions.py        # Solution orchestration

Transferred: 2.2 KB (full context)â”‚   â”‚   â”œâ”€â”€ chat.py             # Chat sessions

Reduction: 0%â”‚   â”‚   â”œâ”€â”€ agents.py           # Agent management

Method: Conversational bufferâ”‚   â”‚   â””â”€â”€ tools.py            # Tool management

```â”‚   â”œâ”€â”€ services/               # Core services

â”‚   â”‚   â”œâ”€â”€ orchestrator.py     # Workflow execution engine

**Research Mode:**â”‚   â”‚   â”œâ”€â”€ metrics_service.py  # Metrics tracking

```â”‚   â”‚   â”œâ”€â”€ kag_service.py      # Knowledge-aided generation

Original: 4.94 KBâ”‚   â”‚   â”œâ”€â”€ gemini_client.py    # Gemini LLM client

Transferred: 200 bytes (top-K chunks)â”‚   â”‚   â””â”€â”€ output_formatter.py # Output formatting

Reduction: 96%â”‚   â””â”€â”€ models/                 # Pydantic models

Method: TF-IDF similarity searchâ”œâ”€â”€ frontend/

```â”‚   â””â”€â”€ src/

â”‚       â”œâ”€â”€ components/         # React components

---â”‚       â”‚   â”œâ”€â”€ Workflows.js    # Workflow manager

â”‚       â”‚   â”œâ”€â”€ Solutions.js    # Solution executor

## ðŸŽ¯ Use Casesâ”‚       â”‚   â”œâ”€â”€ MetricsDisplay.js # Metrics visualization

â”‚       â”‚   â””â”€â”€ ...

### Normal Mode (KAG) - Best For:â”‚       â””â”€â”€ services/           # API clients

â”œâ”€â”€ config/                     # YAML configurations

âœ… **Customer Support Pipeline**â”‚   â”œâ”€â”€ tools/                  # Tool definitions

- Extract customer facts â†’ Analyze sentiment â†’ Generate responsesâ”‚   â”œâ”€â”€ agents/                 # Agent definitions

â”‚   â”œâ”€â”€ workflows/              # Workflow definitions

âœ… **Financial Analysis**â”‚   â”œâ”€â”€ solutions/              # Solution definitions

- Collect market data â†’ Identify trends â†’ Create reportsâ”‚   â””â”€â”€ runs/                   # Execution history

â””â”€â”€ tests/                      # Test files

âœ… **Content Moderation**```

- Scan content â†’ Extract violations â†’ Generate actions

---

### Research Mode (RAG) - Best For:

## ðŸ“„ License

âœ… **Academic Literature Review**

- Scrape papers â†’ Agent analyzes â†’ Synthesize findingsThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.



âœ… **Legal Document Analysis**---

- Extract documents â†’ Agent reviews â†’ Summary reports

## ðŸ™ Acknowledgments

âœ… **News Aggregation**

- Collect articles â†’ Agent identifies themes â†’ Create digest- **LangGraph** for workflow orchestration

- **FastAPI** for the backend framework

---- **React Flow** for workflow visualization

- **Groq**, **Google Gemini**, **Anthropic** for LLM APIs

## ðŸ› ï¸ API Examples

---

### Create a Solution

## ðŸ“ž Support

```python

import requests- **Issues**: [GitHub Issues](https://github.com/Tharunkumar1724/agentic-orchestration-system/issues)

- **Discussions**: [GitHub Discussions](https://github.com/Tharunkumar1724/agentic-orchestration-system/discussions)

# Normal Mode Solution- **Documentation**: Check the `/docs` folder and markdown files in the repository

normal_solution = {

    "name": "Market Analysis",---

    "description": "Analyze market trends",

    "solution_type": "normal",  # KAG + Buffer## ðŸ—ºï¸ Roadmap

    "workflows": ["workflow_1", "workflow_2"]

}- [ ] **v1.0**: First stable release with full metrics system

- [ ] **v1.1**: Enhanced tool templates (15+)

response = requests.post(- [ ] **v1.2**: Multi-LLM parallel execution

    "http://localhost:8000/solutions/",- [ ] **v1.3**: Advanced KAG with RAG integration

    json=normal_solution- [ ] **v2.0**: Production deployment templates (Docker, K8s)

)

---

# Research Mode Solution

research_solution = {**Built with â¤ï¸ by [Tharunkumar1724](https://github.com/Tharunkumar1724)**

    "name": "Research Paper Analysis",

    "description": "Analyze academic papers",â­ **Star this repo if you find it useful!**

    "solution_type": "research",  # Agentic RAG
    "workflows": ["paper_scraper", "literature_review"]
}

response = requests.post(
    "http://localhost:8000/solutions/",
    json=research_solution
)
```

### Execute a Solution

```python
# Execute and get real-time results
response = requests.post(
    f"http://localhost:8000/solutions/{solution_id}/execute",
    params={"query": "Analyze Q4 2024 tech sector"}
)

results = response.json()
print(f"Solution Type: {results['solution_type']}")
print(f"Workflows Executed: {len(results['execution_results'])}")
print(f"Total Cost: ${results['aggregated_metrics']['estimated_cost']}")
```

---

## ðŸ§ª Testing

### Run Agentic RAG Test

```bash
python test_agentic_rag_detailed.py
```

**Output:**
- Complete data flow through workflows
- Chunking and TF-IDF processing
- Agent memory initialization
- Data transfer statistics (96% reduction confirmed)

### Run Mode Comparison

```bash
python test_mode_comparison.py
```

**Output:**
- Side-by-side comparison of Normal vs Research
- Cost differences ($$ vs $0)
- Performance metrics
- Data transfer efficiency

### Run Chunking Demo

```bash
python demo_chunking_strategy.py
```

**Output:**
- Different chunk sizes (50, 100, 200, 300 words)
- Impact on retrieval
- Visual chunk distribution
- Boundary analysis

---

## ðŸ“ Project Structure

```
agentic_app/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ solutions.py          # Solution CRUD + execution
â”‚   â”‚   â”œâ”€â”€ workflows.py          # Workflow management
â”‚   â”‚   â””â”€â”€ chat.py               # Chat endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ kag_service.py        # KAG + Buffer implementation
â”‚   â”‚   â”œâ”€â”€ agentic_rag_service.py # Agentic RAG implementation
â”‚   â”‚   â”œâ”€â”€ gemini_client.py      # Gemini LLM client
â”‚   â”‚   â””â”€â”€ orchestrator.py       # Workflow orchestrator
â”‚   â”œâ”€â”€ models.py                 # Pydantic models
â”‚   â””â”€â”€ storage.py                # JSON file storage
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ SolutionsManagement.js  # Solution UI
â”‚       â”‚   â”œâ”€â”€ SolutionsExecutor.js    # Execution UI
â”‚       â”‚   â””â”€â”€ SolutionExecutionView.js # Real-time view
â”‚       â””â”€â”€ services/
â”‚           â””â”€â”€ api.js            # API client
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_agentic_rag_detailed.py
â”‚   â”œâ”€â”€ test_mode_comparison.py
â”‚   â””â”€â”€ demo_chunking_strategy.py
â”œâ”€â”€ run.py                        # Backend entry point
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ“š Comprehensive Documentation

### Core Guides

- **`SOLUTION_TYPES_EXPLAINED.md`** - In-depth comparison of solution modes
- **`SOLUTION_TYPES_VISUAL_COMPARISON.md`** - Visual diagrams and workflows
- **`SOLUTION_TYPES_QUICK_REF.md`** - Quick reference card

### Technical Deep Dives

- **`HOW_AGENTIC_RAG_WORKS_COMPLETE.md`** - Complete RAG technical guide
- **`AGENTIC_RAG_TEST_RESULTS_DETAILED.md`** - Test results with visualizations
- **`CHUNKING_STRATEGY_EXPLAINED.md`** - Chunking strategy analysis
- **`KAG_LANGGRAPH_GUIDE.md`** - KAG and LangGraph implementation
- **`LIGHTWEIGHT_RAG_IMPLEMENTATION.md`** - RAG implementation details

### Feature Guides

- **`DYNAMIC_TOOLS_COMPLETE.md`** - Dynamic tool creation
- **`METRICS_SYSTEM_COMPLETE.md`** - Metrics tracking system
- **`SOLUTION_SYSTEM_COMPLETE.md`** - Solution architecture
- **`WORKFLOW_COMMUNICATION_COMPLETE.md`** - Inter-workflow communication

---

## ðŸ”‘ Key Decision Guide

### When to Choose Normal Mode (KAG):

âœ… Need intelligent fact extraction  
âœ… Want LLM-powered reasoning  
âœ… Small to medium outputs  
âœ… Real-time context important  
âœ… Budget allows LLM usage  

### When to Choose Research Mode (RAG):

âœ… Large documents (papers, articles)  
âœ… Need to minimize costs  
âœ… Want efficient chunking/indexing  
âœ… Agent needs full context upfront  
âœ… Research and analysis workflows  

---

## ðŸŽ‰ Achievements

### System Capabilities
- âœ… **Dual intelligence modes** - KAG and RAG fully implemented
- âœ… **96% data reduction** - Efficient RAG transfer
- âœ… **Zero LLM costs** - RAG mode requires no API calls
- âœ… **Full context delivery** - Agents receive complete info at startup
- âœ… **Production-ready** - Both modes tested and validated

### Technical Innovations
- âœ… **TF-IDF embeddings** - No LLM needed for retrieval
- âœ… **Smart chunking** - 200-word optimal strategy
- âœ… **LangGraph integration** - Structured workflow pipelines
- âœ… **WebSocket support** - Real-time execution monitoring
- âœ… **Comprehensive metrics** - 12+ tracked metrics

---

## ðŸ¤ Contributing

Contributions are welcome! Please see `CONTRIBUTING.md` for guidelines.

---

## ðŸ“„ License

This project is licensed under the MIT License - see `LICENSE` file for details.

---

## ðŸŒŸ Credits

**Developer:** Tharunkumar1724  
**Repository:** [agentic-orchestration-system](https://github.com/Tharunkumar1724/agentic-orchestration-system)

**Technologies Used:**
- **Backend:** FastAPI, Python 3.8+, LangGraph
- **Frontend:** React 18, TailwindCSS, Axios
- **AI/ML:** Google Gemini, TF-IDF, Cosine Similarity
- **Architecture:** REST + WebSocket, Microservices

---

## ðŸ“ž Support

For questions or issues:
- Open a [GitHub Issue](https://github.com/Tharunkumar1724/agentic-orchestration-system/issues)
- Check the comprehensive documentation in the `/docs` folder

---

**Last Updated:** November 11, 2025  
**Version:** 1.0.0  
**Status:** âœ… Production Ready

---

## ðŸš€ Quick Links

- [Getting Started](GETTING_STARTED.md)
- [API Documentation](API_EXAMPLES.md)
- [Solution Types Guide](SOLUTION_TYPES_EXPLAINED.md)
- [Test Results](AGENTIC_RAG_TEST_RESULTS_DETAILED.md)
- [Contributing Guidelines](CONTRIBUTING.md)

**Happy Orchestrating! ðŸ¤–âœ¨**
